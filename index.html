<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="">
  <meta name="keywords" content="NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Fused-Planes</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>

<body>
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Fused-Planes: <br>Improving Planar Representations <br> for Learning Large Sets of 3D Scenes</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=0dObvuYAAAAJ&hl=fr" target="_blank" rel="noopener noreferrer">Karim Kassab</a><sup>* 1,2</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.fr/citations?user=CcjdVBgAAAAJ&hl=fr" target="_blank" rel="noopener noreferrer">Antoine Schnepf</a><sup>* 1,3</sup>,</span>
            <span class="author-block">
              <a href="https://jyfranceschi.fr/" target="_blank" rel="noopener noreferrer">Jean-Yves Franceschi</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=N0YTGr8AAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Laurent Caraffa</a><sup>2</sup>,
            </span>
            <br>
            <span class="author-block">
              <a href="https://scholar.google.fr/citations?user=L7qb6ToAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Flavian Vasile</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.fr/citations?user=T3dQRjAAAAAJ&hl=fr" target="_blank" rel="noopener noreferrer">Jeremie Mary</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=8UW2vacAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Andrew Comport</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.fr/citations?user=mqq6zX4AAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Valérie Gouet-Brunet</a><sup>2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>* </sup>equal contribution</span><br>
            <span class="author-block"><sup>1 </sup>Criteo AI Lab, Paris, France</span><br>
            <span class="author-block"><sup>2 </sup>LASTIG, Université Gustave Eiffel, IGN-ENSG, F-94160 Saint-Mandé</span><br>
            <span class="author-block"><sup>3 </sup>Université Côte d’Azur, CNRS, I3S, France</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2410.23742v2"
                   class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://arxiv.org/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/k-kassab/scaled-ig"
                   class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data (coming soon)</span>
                  </a> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

<!-- ### -->
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <video id="large-scale" autoplay muted loop playsinline height="100%">
          <source src="./static/videos/ls_video.mp4"
                  type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          To learn large sets of scenes, Tri-Planes are commonly employed for their planar structure that enables an interoperability with image models, and thus diverse 3D applications.
          However, this advantage comes at the cost of resource efficiency, as Tri-Planes are not the most computationally efficient option.
          In this paper, we introduce Fused-Planes, a new planar architecture that improves Tri-Planes resource-efficiency in the framework of learning large sets of scenes, which we call "multi-scene inverse graphics".
          To learn a large set of scenes, our method divides it into two subsets and operates as follows: (i) we train the first subset of scenes jointly with a compression model, (ii) we use that compression model to learn the remaining scenes.
          This compression model consists of a 3D-aware latent space in which Fused-Planes are learned, enabling a reduced rendering resolution, and shared structures across scenes that reduce scene representation complexity.
          Fused-Planes present competitive resource costs in multi-scene inverse graphics, while preserving Tri-Planes rendering quality, and maintaining their widely favored planar structure.
          Our codebase is publicly available as open-source.

        </div>
      </div>
    </div>
    <!--/ Abstract -->
  </div>
</section>

<!-- Method -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method</h2>
        <br><br>
        <div class="content has-text-justified">
          <div class="columns is-centered has-text-centered">
            <img src="static/images/learning-many-scenes.svg" alt="Method Scheme" width="75%"/>
          </div>
          <p>
            <b>Fused-Planes architecture and training framework.</b> 
            We learn a set of Fused-Planes \(\mathcal{T} = \{T_i\}\) in the latent space of an autoencoder, denoted by the encoder \(E_\phi\) and the decoder \(D_\psi\).  
            Hence, Fused-Planes render latent images \(\tilde{z}_{i,j}\) with reduced resolution, enabling faster rendering and training. 
            Each Fused-Plane \(T_i\) is split into a micro plane \(T_i^\mathrm{mic}\) which captures scene specific information, and a macro plane \(T_i^\mathrm{mac}\) computed via a weighted summation over \(M\) shared base planes \(\mathcal{B}\), with weights \(W_i\). 
            The shared planes \(\mathcal{B}\) capture common structure across scenes.
            To learn our set of Fused-Planes, we start by training a first subset of micro planes \(\mathcal{T}_1^\mathrm{mic}\), their corresponding weights \(W_i\) and the base planes \(\mathcal{B}\), jointly with the encoder \(E_\phi\) and decoder  \(D_\psi\).
            Subsequently, we learn the remaining scenes by training the micro planes \(\mathcal{T}_2^\mathrm{mic}\) and their corresponding weights \(W_i\) while fine-tuning \(\mathcal{B}\) and \(D_\psi\).
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!--/ Method -->

<!-- Results -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results</h2>
          <h3 class="title is-4">Resource Costs</h3>
          <br><br>
          <div class="columns is-centered has-text-centered">
            <img src="static/images/resource_landscape.svg" alt="Method Scheme" width="70%"/>
          </div>
          <p>
            <b>Overview: NeRF methods for MSIG. </b> Comparison of resource costs and rendering quality across recent works when training a scene. 
            Circle sizes represent the NVS quality.
            Our method presents the lowest training time and memory footprint among all planar representations, while maintaining a similar rendering quality. 
            Fused-Planes-ULW presents the lowest memory requirement.
          </p>
          <br><br>
          <h3 class="title is-4">Comparison with classical Tri-Planes</h3>
          <h4 class="title is-5">Shapenet Cars Scenes</h4>
          <br><br>
          <div class="columns is-centered has-text-centered">
            <figure>
              <video id="large-scale" autoplay muted loop playsinline width="70%">
                <source src="./static/videos/cars/comp_latent/comp_latent_range(506, 512).mp4"
                        type="video/mp4">
              </video>         
              <figcaption>Fused-Planes</figcaption>
            </figure>
          </div>
          <br><br>
          <div class="columns is-centered has-text-centered">
            <figure>
              <video id="large-scale" autoplay muted loop playsinline width="70%">
                <source src="./static/videos/cars/comp_rgb/comp_rgb_range(506, 512).mp4"
                        type="video/mp4">
              </video>
              <figcaption>Tri-Planes</figcaption>
            </figure>
          </div>
          <h4 class="title is-5">Basel Faces Scenes</h4>
          <div class="columns is-centered has-text-centered">
            <figure>
              <video id="large-scale" autoplay muted loop playsinline width="70%">
                <source src="./static/videos/faces/comp_latent/comp_latent_range(506, 512).mp4"
                        type="video/mp4">
              </video>         
              <figcaption>Fused-Planes</figcaption>
            </figure>
          </div>
          <div class="columns is-centered has-text-centered">
            <figure>
              <video id="large-scale" autoplay muted loop playsinline width="70%">
                <source src="./static/videos/faces/comp_rgb/comp_rgb_range(506, 512).mp4"
                        type="video/mp4">
              </video>
              <figcaption>Tri-Planes</figcaption>
            </figure>
          </div>
        </div>
        <br/>
      </div>
  </div>
</section>
<!--/ Results -->

<!-- BibTex -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @article{fused-planes,
        title={{Fused-Planes: Improving Planar Representations for Learning Large Sets of 3D Scenes}}, 
        author={Karim Kassab and Antoine Schnepf and Jean-Yves Franceschi and Laurent Caraffa and Flavian Vasile and Jeremie Mary and Andrew Comport and Valérie Gouet-Brunet},
        journal={arXiv preprint arXiv:2410.23742},
        year={2025}
      }
    </code></pre>
  </div>
</section>
<!--/ BibTex -->


<!-- Thanks -->
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website was built on top of the <a href="https://github.com/nerfies/nerfies.github.io">following template</a>, for which we thank the authors.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>
<!--/ Thanks -->

</body>
</html>
